{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We made slight modifications from the notebook developed by Hyeong Kyu Choi, which can be found at the following link: https://github.com/imhgchoi/ARIMA-LSTM-hybrid-corrcoef-predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading in Stocks\n",
    "\n",
    "We loaded in data from the stocks that we selected from step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 stocks selected\n",
      "['AMGN.csv', 'ATVI.csv', 'COST.csv', 'GILD.csv', 'MDLZ.csv', 'PEP.csv', 'REGN.csv', 'VRTX.csv', 'WBA.csv', 'XEL.csv']\n"
     ]
    }
   ],
   "source": [
    "path = './Selected_Stocks' \n",
    "#path = './Random_Stocks'\n",
    "stock08 = []\n",
    "for file in os.listdir(path):\n",
    "    file_path = path + '/' + file\n",
    "    date = pd.read_csv(file_path)['Date']\n",
    "    stock08.append(file)\n",
    "print(str(len(stock08))+\" stocks selected\")\n",
    "print(stock08)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_price_dict = {}\n",
    "\n",
    "for file in stock08 :\n",
    "    path = './Selected_Stocks/' + file\n",
    "    #path = './Random_Stocks/' + file\n",
    "    df = pd.read_csv(path)\n",
    "    pd.to_datetime(df['Date'])\n",
    "    df = df.set_index(pd.DatetimeIndex(df['Date']))\n",
    "    stock_price_dict[file.split(\".\")[0]] = df['Close']\n",
    "\n",
    "\n",
    "market_path = \"./Selected Indexes/nasdaq_index.csv\"\n",
    "#market_path = \"./Selected Indexes/SP500_index2.csv\"\n",
    "df = pd.read_csv(market_path)\n",
    "pd.to_datetime(df['Date'])\n",
    "df = df.set_index(pd.DatetimeIndex(df['Date']))\n",
    "stock_price_dict['NASDAQ'] = df['Close']\n",
    "#stock_price_dict['SP500'] = df['Close']\n",
    "    \n",
    "stock_price_df = pd.DataFrame(stock_price_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  AMGN       ATVI        COST       GILD       MDLZ  \\\n",
      "Date                                                                  \n",
      "2013-08-30  108.940002  16.320000  111.870003  60.270000  30.670000   \n",
      "2013-09-03  111.010002  16.980000  111.980003  60.919998  30.790001   \n",
      "2013-09-04  113.019997  17.100000  111.500000  61.110001  30.879999   \n",
      "2013-09-05  112.930000  17.170000  114.620003  61.070000  30.740000   \n",
      "2013-09-06  111.010002  16.969999  114.349998  61.119999  30.940001   \n",
      "\n",
      "                  PEP        REGN       VRTX        WBA        XEL  \\\n",
      "Date                                                                 \n",
      "2013-08-30  79.730003  242.309998  75.150002  48.070000  27.920000   \n",
      "2013-09-03  80.199997  259.149994  75.379997  48.740002  27.490000   \n",
      "2013-09-04  79.529999  268.209991  78.300003  49.490002  27.340000   \n",
      "2013-09-05  79.070000  268.640015  78.379997  50.189999  27.270000   \n",
      "2013-09-06  79.260002  267.570007  78.989998  49.459999  27.370001   \n",
      "\n",
      "                 NASDAQ  \n",
      "Date                     \n",
      "2013-08-30  3589.870117  \n",
      "2013-09-03  3612.610107  \n",
      "2013-09-04  3649.040039  \n",
      "2013-09-05  3658.780029  \n",
      "2013-09-06  3660.010010  \n"
     ]
    }
   ],
   "source": [
    "print(stock_price_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_price_df.to_csv(\"./Selected_Stocks_Results/stock08_price.csv\",index_label='Date')\n",
    "#stock_price_df.to_csv(\"./Random_Stocks_Results/stock08_price.csv\",index_label='Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Initial Portfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: This is not our final portfolio, think about this as an initial portfolio, which through this correlation analysis our aim is to narrow it down even more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio = ['AMGN', 'ATVI', 'COST', 'GILD', 'MDLZ', 'PEP', 'REGN', 'VRTX', 'WBA', 'XEL'] # Selected Stocks\n",
    "#portfolio = ['AXP', 'BBY', 'CAG', 'EMR', 'HSY', 'INCY', 'MCK', 'MNST', 'TGT', 'WBA'] # Random Stocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will be used as input for the ARIMA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_corr(item1,item2) :\n",
    "    #import data\n",
    "    stock_price_df = pd.read_csv(\"./Selected_Stocks_Results/stock08_price.csv\")\n",
    "    #stock_price_df = pd.read_csv(\"./Random_Stocks_Results/stock08_price.csv\")\n",
    "    pd.to_datetime(stock_price_df['Date'], format='%Y-%m-%d')\n",
    "    stock_price_df = stock_price_df.set_index(pd.DatetimeIndex(stock_price_df['Date']))\n",
    "    \n",
    "    #calculate\n",
    "    df_pair = pd.concat([stock_price_df[item1], stock_price_df[item2]], axis=1)\n",
    "    df_pair.columns = [item1,item2]\n",
    "    df_corr = df_pair[item1].rolling(window=100).corr(df_pair[item2])\n",
    "    return df_corr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = []\n",
    "for _ in range(100):\n",
    "    indices = []\n",
    "    for k in range(_, 2100,100):\n",
    "        indices.append(k)\n",
    "    index_list.append(indices)\n",
    "\n",
    "data_matrix = []\n",
    "count = 0\n",
    "stocks_a = []\n",
    "stocks_b = []\n",
    "\n",
    "for i in range(10):\n",
    "    for j in range(9-i):\n",
    "        a = portfolio[i]\n",
    "        b = portfolio[9-j]\n",
    "        file_name = a + '_' + b\n",
    "        stocks_a.append(a)\n",
    "        stocks_b.append(b)\n",
    "            \n",
    "        corr_series = rolling_corr(a, b)[99:]\n",
    "        for j in range(1):\n",
    "            corr_strided = list(corr_series[index_list[j]][:21]).copy()\n",
    "            data_matrix.append(corr_strided)\n",
    "            count+=1\n",
    "            if count % 1000 == 0 :\n",
    "                print(str(count)+' items preprocessed')\n",
    "\n",
    "data_matrix = np.transpose(data_matrix)\n",
    "data_dictionary = {}\n",
    "for i in range(len(data_matrix)):\n",
    "    data_dictionary[str(i)] = data_matrix[i]\n",
    "data_df = pd.DataFrame(data_dictionary)\n",
    "data_df.to_csv(\"./Selected_Stocks_Results/dataset.csv\")\n",
    "#data_df.to_csv(\"./Random_Stocks_Results/dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_pairs = pd.DataFrame(stocks_a, stocks_b).reset_index()\n",
    "stock_pairs.columns = [\"stock1\", \"stock2\"]\n",
    "stock_pairs.to_csv(\"./Selected_Stocks_Results/stock_pairs.csv\", index=False)\n",
    "#stock_pairs.to_csv(\"./Random_Stocks_Results/stock_pairs.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
